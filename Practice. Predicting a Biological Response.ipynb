{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#импорт библиотек\n",
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные моделиё\n",
    "from sklearn import tree #деревья решений\n",
    "from sklearn import ensemble #ансамбли\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #сплитование выборки\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import optuna\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_csv(\"../input/bioresponse/train.csv\")\n",
    "data = pd.read_csv('data/_train_sem09.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшим кол-во признаков, так как их слишком много"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA().fit(data)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "750 нам будет достаточно для полнценного описания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Activity'], axis=1)\n",
    "y = data['Activity']\n",
    "\n",
    "selector = SelectKBest(f_regression, k=750)\n",
    "selector.fit(X, y)\n",
    " \n",
    "X = selector.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <center> LogisticRegression\n",
    "\n",
    "Обучаем модели логистической регрессии. Подбираем гиперпараметры с помощью базовых и продвинутых методов оптимизации. Максимальное количество итераций не превышает 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 1, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.03 s\n",
      "Wall time: 20.9 s\n",
      "accuracy на тестовом наборе: 0.77\n",
      "f1_score на тестовом наборе: 0.788\n",
      "Наилучшие значения гиперпараметров: {'C': 0.21000000000000002, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "150 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "42 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "42 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.751      0.75133333 0.75133333        nan        nan        nan\n",
      " 0.76133333 0.761      0.76166667        nan        nan        nan\n",
      " 0.762      0.76133333 0.76133333        nan        nan        nan\n",
      " 0.75566667 0.757      0.75833333        nan        nan        nan\n",
      " 0.75433333 0.75333333 0.752             nan        nan        nan\n",
      " 0.75233333 0.75233333 0.75333333        nan        nan        nan\n",
      " 0.75066667 0.75166667 0.75366667        nan        nan        nan\n",
      " 0.74933333 0.75266667 0.75133333        nan        nan        nan\n",
      " 0.75033333 0.752      0.74933333        nan        nan        nan\n",
      " 0.74833333 0.75133333 0.75              nan        nan        nan\n",
      " 0.73566667 0.73566667 0.75066667 0.75166667 0.75433333 0.75533333\n",
      " 0.761      0.76166667 0.75833333 0.76033333 0.76       0.76033333\n",
      " 0.75866667 0.757      0.75733333 0.758      0.75733333 0.75866667\n",
      " 0.75233333 0.75566667 0.75666667 0.75633333 0.75266667 0.756\n",
      " 0.756      0.75566667 0.75366667 0.75466667 0.75466667 0.757\n",
      " 0.75166667 0.75366667 0.75433333 0.75466667 0.75166667 0.75266667\n",
      " 0.75533333 0.75466667 0.751      0.753     ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "              {'penalty': ['l2', 'none'] , # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag', 'newton-cg'], # алгоритм оптимизации\n",
    "               'C': np.arange(0.01, 1, 0.1)}, # уровень силы регурялизации\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': np.arange(0.01, 1, 0.1)}\n",
    "]\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=50), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_1.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_1.score(X_test, y_test)))\n",
    "y_test_pred = grid_search_1.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_1.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 641 ms\n",
      "Wall time: 11 s\n",
      "accuracy на тестовом наборе: 0.77\n",
      "f1_score на тестовом наборе: 0.788\n",
      "Наилучшие значения гиперпараметров: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.21000000000000002}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "80 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1'} or None. Got 'none' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.75133333 0.75133333        nan 0.75166667\n",
      " 0.757             nan 0.75666667 0.75       0.75366667 0.75733333\n",
      "        nan        nan 0.75333333 0.75166667 0.762      0.756\n",
      " 0.75466667 0.757      0.75266667 0.74833333 0.76166667 0.75133333\n",
      " 0.75466667        nan 0.73566667        nan 0.75366667 0.75633333\n",
      "        nan 0.75033333 0.761             nan 0.74933333 0.761\n",
      "        nan        nan 0.757             nan 0.752      0.76033333\n",
      " 0.75233333 0.751             nan 0.75466667        nan        nan\n",
      " 0.76133333 0.756     ]\n",
      "  warnings.warn(\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "param_distributions = [\n",
    "              {'penalty': ['l2', 'none'] , # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag', 'newton-cg'], # алгоритм оптимизации\n",
    "               'C': np.arange(0.01, 1, 0.1)}, # уровень силы регурялизации\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': np.arange(0.01, 1, 0.1)}\n",
    "]\n",
    "            \n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=50), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5, \n",
    "    n_iter = 50, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search.score(X_test, y_test)))\n",
    "y_test_pred = random_search.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "pen = ['l1', 'l2']\n",
    "sol = ['liblinear', 'saga']\n",
    "space={'penalty': hp.choice('penalty', ['l1', 'l2']), # тип регуляризации\n",
    "       'solver': hp.choice('solver', ['liblinear', 'saga']), # алгоритм оптимизации\n",
    "       'C': hp.uniform('C', low=0.01, high=1) # уровень силы регурялизации\n",
    "      }\n",
    "\n",
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_lr(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'penalty': params['penalty'], \n",
    "              'solver': params['solver'], \n",
    "              'C': float(params['C'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    #score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # обучать модель можно также с помощью кросс-валидации\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:17,  2.74trial/s, best loss: -0.7767986703881459]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:04<01:02,  1.33s/trial, best loss: -0.7798036015647992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:07<01:05,  1.46s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:10<01:20,  1.83s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:13<00:50,  1.22s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:17<00:54,  1.39s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:20<00:51,  1.40s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:24<01:12,  2.01s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:28<01:03,  1.86s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:30<01:07,  2.06s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:34<01:17,  2.43s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:38<00:32,  1.18s/trial, best loss: -0.7843994792274138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:41<00:23,  1.07trial/s, best loss: -0.7845917208966752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:44<00:36,  1.51s/trial, best loss: -0.7845917208966752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:47<00:22,  1.08s/trial, best loss: -0.7845917208966752]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:50<00:30,  1.54s/trial, best loss: -0.7849023547026058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:53<00:35,  1.86s/trial, best loss: -0.7849023547026058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:55<00:37,  2.10s/trial, best loss: -0.7849023547026058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:58<00:38,  2.26s/trial, best loss: -0.7849023547026058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [01:01<00:37,  2.37s/trial, best loss: -0.7849023547026058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:03<00:36,  2.42s/trial, best loss: -0.7849023547026058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [01:06<00:34,  2.46s/trial, best loss: -0.7849023547026058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [01:08<00:33,  2.56s/trial, best loss: -0.7849023547026058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [01:14<00:28,  2.57s/trial, best loss: -0.7849023547026058]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:16<00:25,  2.59s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:19<00:23,  2.58s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [01:21<00:20,  2.60s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [01:24<00:18,  2.64s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [01:27<00:15,  2.62s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:30<00:14,  2.84s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [01:33<00:11,  2.77s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [01:36<00:08,  2.97s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [01:39<00:05,  2.84s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [01:42<00:03,  3.04s/trial, best loss: -0.7858339693659235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:45<00:00,  2.11s/trial, best loss: -0.7858339693659235]\n",
      "Наилучшие значения гиперпараметров {'C': 0.07807657638745155, 'penalty': 1, 'solver': 1}\n",
      "CPU times: total: 51.2 s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_lr, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=50, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.82\n",
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = linear_model.LogisticRegression(\n",
    "    random_state=random_state, \n",
    "    penalty=pen[best['penalty']],\n",
    "    solver=sol[best['solver']],\n",
    "    C=float(best['C'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим оптимизацию гиперпараметров для алгоритма логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_lr(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "  solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "  C = trial.suggest_float('C', low=0.01, high=1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = linear_model.LogisticRegression(penalty=penalty,\n",
    "                                          solver=solver,\n",
    "                                          C=C,\n",
    "                                          random_state=random_state)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  #score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "  \n",
    "  score = cross_val_score(model, X, y, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "  return score\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-15 01:43:00,245] A new study created in memory with name: LogisticRegression\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:04,111] Trial 0 finished with value: 0.782022066225299 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.6107708230126454}. Best is trial 0 with value: 0.782022066225299.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:07,155] Trial 1 finished with value: 0.7872624336194823 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.03711961559831381}. Best is trial 1 with value: 0.7872624336194823.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:10,172] Trial 2 finished with value: 0.7783558732751737 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.6285970744867515}. Best is trial 1 with value: 0.7872624336194823.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:14,023] Trial 3 finished with value: 0.7840991858260031 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.4749164404987482}. Best is trial 1 with value: 0.7872624336194823.\n",
      "[I 2024-12-15 01:43:14,512] Trial 4 finished with value: 0.777677406284837 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.9431545722758891}. Best is trial 1 with value: 0.7872624336194823.\n",
      "[I 2024-12-15 01:43:15,090] Trial 5 finished with value: 0.7799347423389545 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.7532060474332503}. Best is trial 1 with value: 0.7872624336194823.\n",
      "[I 2024-12-15 01:43:15,582] Trial 6 finished with value: 0.7777848958063007 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.8211792179704543}. Best is trial 1 with value: 0.7872624336194823.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:18,572] Trial 7 finished with value: 0.778358741635753 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.6693286553751373}. Best is trial 1 with value: 0.7872624336194823.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:21,489] Trial 8 finished with value: 0.7858778182189452 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.10705313812979624}. Best is trial 1 with value: 0.7872624336194823.\n",
      "[I 2024-12-15 01:43:22,017] Trial 9 finished with value: 0.7797731916789074 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.6066239138292066}. Best is trial 1 with value: 0.7872624336194823.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:24,931] Trial 10 finished with value: 0.7881376026232549 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.023497971398092454}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:27,823] Trial 11 finished with value: 0.7878758811433377 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.025596644690637917}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:30,656] Trial 12 finished with value: 0.7841226270025644 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.24979739958399486}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:33,602] Trial 13 finished with value: 0.7840516710634647 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.29236813380206655}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:36,699] Trial 14 finished with value: 0.7870067741335537 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.17935352669440432}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:39,652] Trial 15 finished with value: 0.7807411733882763 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.39275066631151756}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:42,629] Trial 16 finished with value: 0.7853981197780932 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.013331277979140493}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:45,544] Trial 17 finished with value: 0.7832320948397171 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.32816654536953493}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:43:45,878] Trial 18 finished with value: 0.7849296917806095 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.15354223971739553}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:49,076] Trial 19 finished with value: 0.7805331362492345 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.4573170689563673}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:51,998] Trial 20 finished with value: 0.7847811570937369 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.21225949363142238}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:43:54,791] Trial 21 finished with value: 0.7816802167766255 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.010327621151199689}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:43:57,672] Trial 22 finished with value: 0.7865814896083765 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.08199462800000454}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:00,543] Trial 23 finished with value: 0.7869563849884854 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.08722970655528865}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:03,475] Trial 24 finished with value: 0.7875672347014666 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.033450351828734404}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:06,416] Trial 25 finished with value: 0.7844913711960244 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.14866773946601153}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:06,813] Trial 26 finished with value: 0.7875573763868164 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.30978344852746886}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:09,837] Trial 27 finished with value: 0.78578180200012 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.1146427920719357}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:12,843] Trial 28 finished with value: 0.7850541904533404 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.23338813287876106}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:16,843] Trial 29 finished with value: 0.7851222729997023 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.35525417087789146}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:19,705] Trial 30 finished with value: 0.7857409724287063 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.05511958478157286}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:20,238] Trial 31 finished with value: 0.7863317142737356 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.2849523821204897}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:20,649] Trial 32 finished with value: 0.7839727987249013 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.17134252772019756}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:21,391] Trial 33 finished with value: 0.7815566413514292 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.54339842529164}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:22,097] Trial 34 finished with value: 0.7848983207789731 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.40142712125153707}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:22,366] Trial 35 finished with value: 0.7773850418787852 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.06815027571978963}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:22,692] Trial 36 finished with value: 0.7847725107629192 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.1282736896412382}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:25,541] Trial 37 finished with value: 0.7768780704828314 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.9849795563469711}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:25,767] Trial 38 finished with value: 0.7646997938502007 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.04202342130258464}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:28,657] Trial 39 finished with value: 0.7850679721183385 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.20586071968497668}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:29,098] Trial 40 finished with value: 0.7778585770634179 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.5456306128467378}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:31,899] Trial 41 finished with value: 0.7814946885524983 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.010070856182792881}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:34,837] Trial 42 finished with value: 0.7852980314036244 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.10317016590218969}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:37,930] Trial 43 finished with value: 0.7774595013146299 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.8092157277101961}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:40,882] Trial 44 finished with value: 0.7867684189160686 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.08453039367742712}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:43,779] Trial 45 finished with value: 0.7846041425305 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.26267834254742056}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:46,728] Trial 46 finished with value: 0.785538457271119 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.049913721098329755}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:50,760] Trial 47 finished with value: 0.7816054028479255 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.6899843423101684}. Best is trial 10 with value: 0.7881376026232549.\n",
      "[I 2024-12-15 01:44:51,163] Trial 48 finished with value: 0.7861395277978721 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.18547462415036384}. Best is trial 10 with value: 0.7881376026232549.\n",
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-15 01:44:54,071] Trial 49 finished with value: 0.7845973934883725 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.1348589385809741}. Best is trial 10 with value: 0.7881376026232549.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 49.3 s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_lr, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'penalty': 'l2', 'solver': 'saga', 'C': 0.023497971398092454}\n",
      "f1_score на обучающем наборе: 0.79\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.77\n",
      "f1_score на тестовом наборе: 0.790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = linear_model.LogisticRegression(**study.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <center> RandomForestClassifier\n",
    "\n",
    "Обучаем модели случайного леса. Подбираем гиперпараметры с помощью базовых и продвинутых методов оптимизации. Максимальное количество итераций не превышает 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.00\n",
      "Test: 0.819\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса случайный лес\n",
    "rf = ensemble.RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Обучаем модель\n",
    "rf.fit(X_train, y_train)\n",
    "#Выводим значения метрики \n",
    "y_train_pred = rf.predict(X_train)\n",
    "print('Train: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "y_test_pred = rf.predict(X_test)\n",
    "print('Test: {:.3f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 875 ms\n",
      "Wall time: 19.4 s\n",
      "f1_score на обучающем наборе: 0.94\n",
      "accuracy на тестовом наборе: 0.79\n",
      "f1_score на тестовом наборе: 0.811\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 22, 'min_samples_leaf': 5, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': list(range(50, 170, 30)),\n",
    "              'min_samples_leaf': [5, 7, 10],\n",
    "              'max_depth': list(np.linspace(20, 40, 5, dtype=int))\n",
    "              }\n",
    "            \n",
    "grid_search_forest = GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_grid=param_grid, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_forest.fit(X_train, y_train) \n",
    "y_train_pred = grid_search_forest.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_forest.score(X_test, y_test)))\n",
    "y_test_pred = grid_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHOLFI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 48 is smaller than n_iter=50. Running 48 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 859 ms\n",
      "Wall time: 19.5 s\n",
      "f1_score на обучающем наборе: 0.94\n",
      "accuracy на тестовом наборе: 0.79\n",
      "f1_score на тестовом наборе: 0.811\n",
      "Наилучшие значения гиперпараметров: {'n_estimators': 80, 'min_samples_leaf': 5, 'max_depth': 22}\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {'n_estimators': list(range(50, 170, 30)),\n",
    "              'min_samples_leaf': [5, 7, 10],\n",
    "              'max_depth': list(np.linspace(20, 40, 5, dtype=int))\n",
    "              }\n",
    "            \n",
    "random_search_forest = RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    cv=5,\n",
    "    n_iter = 50, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time random_search_forest.fit(X_train, y_train) \n",
    "y_train_pred = random_search_forest.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(random_search_forest.score(X_test, y_test)))\n",
    "y_test_pred = random_search_forest.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(random_search_forest.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим пространство поиска гиперпараметров\n",
    "space={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    #score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    score = cross_val_score(model, X, y, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:46<00:00,  2.13s/trial, best loss: -0.8167441020057085]\n",
      "Наилучшие значения гиперпараметров {'max_depth': 21.0, 'min_samples_leaf': 3.0, 'n_estimators': 170.0}\n",
      "CPU times: total: 50.9 s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_rf, # наша функция \n",
    "          space=space, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=50, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.97\n",
      "accuracy на тестовом наборе: 0.80\n",
      "f1_score на тестовом наборе: 0.823\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настроим оптимизацию гиперпараметров для алгоритма случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
    "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          random_state=random_state)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  #score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "  \n",
    "  score = cross_val_score(model, X, y, cv=5, scoring=\"f1\", n_jobs=-1).mean()\n",
    "  return score\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-15 01:47:22,872] A new study created in memory with name: RandomForestClassifier\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:25,594] Trial 0 finished with value: 0.799697559638032 and parameters: {'n_estimators': 197, 'max_depth': 26, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.799697559638032.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:27,769] Trial 1 finished with value: 0.796428058587082 and parameters: {'n_estimators': 158, 'max_depth': 23, 'min_samples_leaf': 10}. Best is trial 0 with value: 0.799697559638032.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:29,725] Trial 2 finished with value: 0.7990462315626348 and parameters: {'n_estimators': 135, 'max_depth': 21, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.799697559638032.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:32,174] Trial 3 finished with value: 0.7982965161386308 and parameters: {'n_estimators': 180, 'max_depth': 12, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.799697559638032.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:34,924] Trial 4 finished with value: 0.8119145676066907 and parameters: {'n_estimators': 178, 'max_depth': 24, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.8119145676066907.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:36,623] Trial 5 finished with value: 0.8091633545304695 and parameters: {'n_estimators': 107, 'max_depth': 16, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.8119145676066907.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:38,974] Trial 6 finished with value: 0.8128529477788711 and parameters: {'n_estimators': 143, 'max_depth': 28, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.8128529477788711.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:40,654] Trial 7 finished with value: 0.8029523646338209 and parameters: {'n_estimators': 113, 'max_depth': 23, 'min_samples_leaf': 8}. Best is trial 6 with value: 0.8128529477788711.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:43,250] Trial 8 finished with value: 0.8056344450059665 and parameters: {'n_estimators': 180, 'max_depth': 14, 'min_samples_leaf': 7}. Best is trial 6 with value: 0.8128529477788711.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:45,399] Trial 9 finished with value: 0.8064705273245792 and parameters: {'n_estimators': 141, 'max_depth': 12, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.8128529477788711.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:47,669] Trial 10 finished with value: 0.8131035860190433 and parameters: {'n_estimators': 126, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.8131035860190433.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:49,974] Trial 11 finished with value: 0.8127936416214219 and parameters: {'n_estimators': 125, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.8131035860190433.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:52,773] Trial 12 finished with value: 0.812651182862456 and parameters: {'n_estimators': 156, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 10 with value: 0.8131035860190433.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:54,988] Trial 13 finished with value: 0.8131480541323187 and parameters: {'n_estimators': 127, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8131480541323187.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:57,061] Trial 14 finished with value: 0.808696860565977 and parameters: {'n_estimators': 121, 'max_depth': 18, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8131480541323187.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:47:58,862] Trial 15 finished with value: 0.8100866710514014 and parameters: {'n_estimators': 101, 'max_depth': 27, 'min_samples_leaf': 3}. Best is trial 13 with value: 0.8131480541323187.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:00,847] Trial 16 finished with value: 0.808701563056144 and parameters: {'n_estimators': 128, 'max_depth': 26, 'min_samples_leaf': 6}. Best is trial 13 with value: 0.8131480541323187.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:02,979] Trial 17 finished with value: 0.8121193525629078 and parameters: {'n_estimators': 115, 'max_depth': 30, 'min_samples_leaf': 2}. Best is trial 13 with value: 0.8131480541323187.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:05,582] Trial 18 finished with value: 0.8144435573057617 and parameters: {'n_estimators': 149, 'max_depth': 21, 'min_samples_leaf': 3}. Best is trial 18 with value: 0.8144435573057617.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:08,282] Trial 19 finished with value: 0.8147847737323681 and parameters: {'n_estimators': 166, 'max_depth': 19, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.8147847737323681.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:10,862] Trial 20 finished with value: 0.8105085983698818 and parameters: {'n_estimators': 163, 'max_depth': 19, 'min_samples_leaf': 5}. Best is trial 19 with value: 0.8147847737323681.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:13,597] Trial 21 finished with value: 0.8126390441595746 and parameters: {'n_estimators': 167, 'max_depth': 21, 'min_samples_leaf': 4}. Best is trial 19 with value: 0.8147847737323681.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:16,046] Trial 22 finished with value: 0.8148355155187093 and parameters: {'n_estimators': 147, 'max_depth': 17, 'min_samples_leaf': 3}. Best is trial 22 with value: 0.8148355155187093.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:18,541] Trial 23 finished with value: 0.8150291219011633 and parameters: {'n_estimators': 149, 'max_depth': 17, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.8150291219011633.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:21,209] Trial 24 finished with value: 0.8104152195150991 and parameters: {'n_estimators': 169, 'max_depth': 16, 'min_samples_leaf': 4}. Best is trial 23 with value: 0.8150291219011633.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:23,507] Trial 25 finished with value: 0.8055429661656112 and parameters: {'n_estimators': 150, 'max_depth': 17, 'min_samples_leaf': 6}. Best is trial 23 with value: 0.8150291219011633.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:26,342] Trial 26 finished with value: 0.8150182224655301 and parameters: {'n_estimators': 174, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.8150291219011633.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:29,048] Trial 27 finished with value: 0.8042354994892664 and parameters: {'n_estimators': 194, 'max_depth': 10, 'min_samples_leaf': 3}. Best is trial 23 with value: 0.8150291219011633.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:31,134] Trial 28 finished with value: 0.8067426926787352 and parameters: {'n_estimators': 137, 'max_depth': 14, 'min_samples_leaf': 6}. Best is trial 23 with value: 0.8150291219011633.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:34,161] Trial 29 finished with value: 0.809848144131078 and parameters: {'n_estimators': 200, 'max_depth': 14, 'min_samples_leaf': 5}. Best is trial 23 with value: 0.8150291219011633.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:37,385] Trial 30 finished with value: 0.8127843042666558 and parameters: {'n_estimators': 189, 'max_depth': 16, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.8150291219011633.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:40,208] Trial 31 finished with value: 0.8162853072446674 and parameters: {'n_estimators': 174, 'max_depth': 18, 'min_samples_leaf': 4}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:43,105] Trial 32 finished with value: 0.8143686811430312 and parameters: {'n_estimators': 174, 'max_depth': 18, 'min_samples_leaf': 3}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:45,614] Trial 33 finished with value: 0.8152559825707962 and parameters: {'n_estimators': 157, 'max_depth': 17, 'min_samples_leaf': 4}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:48,175] Trial 34 finished with value: 0.81338684271087 and parameters: {'n_estimators': 157, 'max_depth': 20, 'min_samples_leaf': 4}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:51,006] Trial 35 finished with value: 0.8114701786751324 and parameters: {'n_estimators': 187, 'max_depth': 15, 'min_samples_leaf': 5}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:53,623] Trial 36 finished with value: 0.8089527757294125 and parameters: {'n_estimators': 174, 'max_depth': 12, 'min_samples_leaf': 4}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:55,812] Trial 37 finished with value: 0.7924867327406109 and parameters: {'n_estimators': 159, 'max_depth': 13, 'min_samples_leaf': 10}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:48:58,177] Trial 38 finished with value: 0.7985877240872867 and parameters: {'n_estimators': 173, 'max_depth': 10, 'min_samples_leaf': 6}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:00,885] Trial 39 finished with value: 0.8027858515629435 and parameters: {'n_estimators': 185, 'max_depth': 23, 'min_samples_leaf': 7}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:03,382] Trial 40 finished with value: 0.8101792681415267 and parameters: {'n_estimators': 161, 'max_depth': 15, 'min_samples_leaf': 5}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:05,916] Trial 41 finished with value: 0.8152229402780307 and parameters: {'n_estimators': 151, 'max_depth': 17, 'min_samples_leaf': 3}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:08,488] Trial 42 finished with value: 0.8137737275065013 and parameters: {'n_estimators': 152, 'max_depth': 17, 'min_samples_leaf': 3}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:11,016] Trial 43 finished with value: 0.812120622582374 and parameters: {'n_estimators': 144, 'max_depth': 19, 'min_samples_leaf': 2}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:13,509] Trial 44 finished with value: 0.8149225152494617 and parameters: {'n_estimators': 154, 'max_depth': 18, 'min_samples_leaf': 4}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:15,856] Trial 45 finished with value: 0.8108245206594589 and parameters: {'n_estimators': 139, 'max_depth': 15, 'min_samples_leaf': 3}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:18,254] Trial 46 finished with value: 0.8127548032176474 and parameters: {'n_estimators': 133, 'max_depth': 21, 'min_samples_leaf': 2}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:21,105] Trial 47 finished with value: 0.813509116487024 and parameters: {'n_estimators': 183, 'max_depth': 13, 'min_samples_leaf': 4}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:24,063] Trial 48 finished with value: 0.8136778826399043 and parameters: {'n_estimators': 179, 'max_depth': 16, 'min_samples_leaf': 3}. Best is trial 31 with value: 0.8162853072446674.\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:3: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
      "C:\\Users\\SHOLFI\\AppData\\Local\\Temp\\ipykernel_15968\\3494334642.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
      "[I 2024-12-15 01:49:26,473] Trial 49 finished with value: 0.8166663290260431 and parameters: {'n_estimators': 133, 'max_depth': 20, 'min_samples_leaf': 2}. Best is trial 49 with value: 0.8166663290260431.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 52.3 s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cоздаем объект исследования\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study.optimize(optuna_rf, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 133, 'max_depth': 20, 'min_samples_leaf': 2}\n",
      "f1_score на обучающем наборе: 0.82\n"
     ]
    }
   ],
   "source": [
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study.best_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на тестовом наборе: 0.80\n",
      "f1_score на тестовом наборе: 0.819\n"
     ]
    }
   ],
   "source": [
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_test, y_test)))\n",
    "y_test_pred = model.predict(X_test)\n",
    "print('f1_score на тестовом наборе: {:.3f}'.format(metrics.f1_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train = pd.read_csv(\"../input/bioresponse/train.csv\")\\nX_test =  pd.read_csv(\"../input/bioresponse/test.csv\")\\n\\ny_train = X_train[\"Activity\"]\\n\\nX_train.drop(columns=[\"Activity\"],inplace=True)\\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train = pd.read_csv(\"../input/bioresponse/train.csv\")\n",
    "X_test =  pd.read_csv(\"../input/bioresponse/test.csv\")\n",
    "\n",
    "y_train = X_train[\"Activity\"]\n",
    "\n",
    "X_train.drop(columns=[\"Activity\"],inplace=True)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier(n_estimators = 110, min_samples_leaf = 5, max_depth = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)\n",
    "\n",
    "predicted_prob = model.predict_proba(X_test)\n",
    "\n",
    "Probability = predicted_prob[:,1]\n",
    "MoleculeId = np.array(range(1,len(X_test)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"MoleculeId\"] = MoleculeId\n",
    "submission['PredictedProbability'] = Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MoleculeId  PredictedProbability\n",
      "0             1              0.492342\n",
      "1             2              0.726856\n",
      "2             3              0.173709\n",
      "3             4              0.774189\n",
      "4             5              0.830927\n",
      "..          ...                   ...\n",
      "746         747              0.843204\n",
      "747         748              0.767367\n",
      "748         749              0.913551\n",
      "749         750              0.405257\n",
      "750         751              0.782493\n",
      "\n",
      "[751 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
